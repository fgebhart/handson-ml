{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Iris Data Set\n",
    "\n",
    "* 50 samples of 3 different species of iris (150 samples total)\n",
    "* Measurements: sepal length, sepal width, petal length, petal width\n",
    "\n",
    "My notes to the scikitlearn tutorial using the Iris dataset, see https://github.com/justmarkham/scikit-learn-videos\n",
    "\n",
    "## Loading the iris dataset into scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:13:58.518932Z",
     "start_time": "2018-12-16T15:13:58.512545Z"
    }
   },
   "outputs": [],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:13:59.067259Z",
     "start_time": "2018-12-16T15:13:59.059073Z"
    }
   },
   "outputs": [],
   "source": [
    "# save \"bunch\" object containing iris dataset and its attributes\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us basically two data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:13:59.922750Z",
     "start_time": "2018-12-16T15:13:59.873403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:00.649870Z",
     "start_time": "2018-12-16T15:14:00.636930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:02.386836Z",
     "start_time": "2018-12-16T15:14:02.374791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the type of the data set is a numpy array we can easily check the shape of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:06.175608Z",
     "start_time": "2018-12-16T15:14:06.167228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means the data contains 150 rows with 4 columns. These are the dimensions of the flower leafs, i.e. the Measurements of sepal length, sepal width, petal length, petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:08.439113Z",
     "start_time": "2018-12-16T15:14:08.429859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target contains the labels only. Namely the names of the iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:09.568257Z",
     "start_time": "2018-12-16T15:14:09.561691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lables:  ['setosa' 'versicolor' 'virginica']\n",
      "features:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(\"lables: \", iris.target_names)\n",
    "print(\"features: \", iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We frame this as a supervised classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the data for the subsequent fitting. X is the feature matrix and y is the label vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:11.745414Z",
     "start_time": "2018-12-16T15:14:11.739568Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We will try different estimators like\n",
    "* K-nearest-neighbors\n",
    "* Logistic Regression\n",
    "* ... ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors (KNN)\n",
    "\n",
    "for more info see: https://github.com/justmarkham/scikit-learn-videos/blob/master/04_model_training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create instance of classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:32.707975Z",
     "start_time": "2018-12-16T15:14:32.699815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. train the model**\n",
    "\n",
    "fit the data = model is learning the relationship between X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:22.124443Z",
     "start_time": "2018-12-16T15:14:22.116491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. predict response for new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "new_data = [[3, 5, 4, 2]]\n",
    "y_knn1 = knn.predict(new_data)\n",
    "print(y_knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means the measurements in `new_data` are a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names[y_knn1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this for a bigger data set not only for single datum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = [[3, 5, 4, 2], [5, 4, 3, 2]]\n",
    "y_knn1 = knn.predict(X_new)\n",
    "y_knn1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could also use another value for K: (K is the number of nearest neighbors to take into account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_knn5 = knn.predict(X_new)\n",
    "y_knn5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(multi_class='auto', solver='liblinear')\n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "y_logreg = logreg.predict(X_new)\n",
    "y_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> 3 different classifier = 3 different solutions!?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of different models\n",
    "\n",
    "\n",
    "### Training and testing on whole (same) data set\n",
    "\n",
    "to evaluate a model we use the sklearn `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the above models on the whole data set and then test them on *the same* data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_logreg =logreg.predict(X)\n",
    "metrics.accuracy_score(y, y_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_knn5 = knn.predict(X)\n",
    "metrics.accuracy_score(y, y_knn5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "y_knn1 = knn.predict(X)\n",
    "metrics.accuracy_score(y, y_knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN with K=1 gives a accuracy of 100%. Which does not mean we trained a perfect model, rather than showing us the problem of training and testing on the same data. KNN basically looks for each training instance which is the closest neighbor, which in fact is the same instance out of the training set. Therefore it predicts each instance of the testing set correctyl... **methodological error!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "In order to overcome the above problem we split the data set into a dedicated training and a dedicated test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that y is only the responses / labels of the species of flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:  [0 1 0 1 2 1 2 1 0 2 2 0 1 2 0 2 1 2 1 0 2 1 2 0 2 1 2 1 2 1 1 2 1 1 2 1 1\n",
      " 0 2 0 1 0 1 1 1 1 0 2 2 1 1 1 0 0 2 2 0 0 0 2 0 0 2 2 1 0 0 0 2 1 0 0 2 1\n",
      " 2 0 0 2 1 1 1 2 2 1 2 1 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train: \", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model on the train set: `X_train` and the corresponding `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and test it on the dedicated test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 0, 1, 0,\n",
       "       2, 0, 0, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_logreg_tt = logreg.predict(X_test)\n",
    "y_logreg_tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_logreg_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the KNN Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_knn5_tt = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_knn5_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_knn1_tt = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_knn1_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finally see the performance of the three different classifier and are able to compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Testing accuracy is a high variance estimate, the accuracy value strongly variates with the choice of the `random_state` value for splitting the test set. Therefore one could naturally think of splitting the test set in multiple different train and test sets and then averaging over all accuracy values. This is basically what **Cross Validation** does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:39.815825Z",
     "start_time": "2018-12-16T15:14:39.780372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the `cross_validation_score` we do not need to take care of splitting the data set into train and test set. The cross validation function takes care of this since it splits the data set into the mentioned k-folds. The given list contains all accuracys of each fold. To get the mean we use the numpy function `mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:41.257757Z",
     "start_time": "2018-12-16T15:14:41.251938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Parameter tuning\n",
    "\n",
    "To find the best value for `n_neighbors` for KNN in terms of highest accuracy we can simply try a range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:42.765528Z",
     "start_time": "2018-12-16T15:14:42.125637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96, 0.9533333333333334, 0.9666666666666666, 0.9666666666666666, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9800000000000001, 0.9666666666666666, 0.9666666666666666, 0.9733333333333334, 0.96, 0.9666666666666666, 0.96, 0.9666666666666666, 0.9533333333333334, 0.9533333333333334, 0.9533333333333334]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:44.694970Z",
     "start_time": "2018-12-16T15:14:43.996989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-Validated Accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing so we find the best value for K to be between 13 and 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Model Selection\n",
    "\n",
    "Quickly estimate the accuracy of a model and compare it with the accuracy of another model to figure out which one to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:47.058432Z",
     "start_time": "2018-12-16T15:14:47.014555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:48.511217Z",
     "start_time": "2018-12-16T15:14:48.391992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(multi_class='auto')\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Feature Selection\n",
    "\n",
    "We can also use cross validation to selection certain features of a data set. Simply validate your data set with and without certain features and compare the resulting accuracies. For more info see: https://github.com/justmarkham/scikit-learn-videos/blob/master/07_cross_validation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Grid Search for Parameter Tuning\n",
    "\n",
    "Instead of running a for loop over a range of parameters like described in above in \"Cross Validatino for Parameter Tuning\" we can also use the `scikitlearn` module `GridSearchCV` which does exactly this. It allows you to define a grid of parameters that will be searched using K-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:14:50.868920Z",
     "start_time": "2018-12-16T15:14:50.865719Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the parameter values that should be searched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 31))\n",
    "print(k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a parameter grid (a dict): map the parameter names to the values that should be searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(knn,\n",
    "                    param_grid, cv=10,\n",
    "                    scoring='accuracy',\n",
    "                    return_train_score=False,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set n_jobs = -1 to run computations in parallel (if supported by your computer and OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the grid with data\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use the `grid` attribute `cv_results_` and display it using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score               params\n",
       "0          0.960000        0.053333   {'n_neighbors': 1}\n",
       "1          0.953333        0.052068   {'n_neighbors': 2}\n",
       "2          0.966667        0.044721   {'n_neighbors': 3}\n",
       "3          0.966667        0.044721   {'n_neighbors': 4}\n",
       "4          0.966667        0.044721   {'n_neighbors': 5}\n",
       "5          0.966667        0.044721   {'n_neighbors': 6}\n",
       "6          0.966667        0.044721   {'n_neighbors': 7}\n",
       "7          0.966667        0.044721   {'n_neighbors': 8}\n",
       "8          0.973333        0.032660   {'n_neighbors': 9}\n",
       "9          0.966667        0.044721  {'n_neighbors': 10}\n",
       "10         0.966667        0.044721  {'n_neighbors': 11}\n",
       "11         0.973333        0.032660  {'n_neighbors': 12}\n",
       "12         0.980000        0.030551  {'n_neighbors': 13}\n",
       "13         0.973333        0.044222  {'n_neighbors': 14}\n",
       "14         0.973333        0.032660  {'n_neighbors': 15}\n",
       "15         0.973333        0.032660  {'n_neighbors': 16}\n",
       "16         0.973333        0.032660  {'n_neighbors': 17}\n",
       "17         0.980000        0.030551  {'n_neighbors': 18}\n",
       "18         0.973333        0.032660  {'n_neighbors': 19}\n",
       "19         0.980000        0.030551  {'n_neighbors': 20}\n",
       "20         0.966667        0.033333  {'n_neighbors': 21}\n",
       "21         0.966667        0.033333  {'n_neighbors': 22}\n",
       "22         0.973333        0.032660  {'n_neighbors': 23}\n",
       "23         0.960000        0.044222  {'n_neighbors': 24}\n",
       "24         0.966667        0.033333  {'n_neighbors': 25}\n",
       "25         0.960000        0.044222  {'n_neighbors': 26}\n",
       "26         0.966667        0.044721  {'n_neighbors': 27}\n",
       "27         0.953333        0.042687  {'n_neighbors': 28}\n",
       "28         0.953333        0.042687  {'n_neighbors': 29}\n",
       "29         0.953333        0.042687  {'n_neighbors': 30}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results as a pandas DataFrame\n",
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# examine the first result\n",
    "print(grid.cv_results_['params'][0])\n",
    "print(grid.cv_results_['mean_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96       0.95333333 0.96666667 0.96666667 0.96666667 0.96666667\n",
      " 0.96666667 0.96666667 0.97333333 0.96666667 0.96666667 0.97333333\n",
      " 0.98       0.97333333 0.97333333 0.97333333 0.97333333 0.98\n",
      " 0.97333333 0.98       0.96666667 0.96666667 0.97333333 0.96\n",
      " 0.96666667 0.96       0.96666667 0.95333333 0.95333333 0.95333333]\n"
     ]
    }
   ],
   "source": [
    "# print the array of mean scores only\n",
    "grid_mean_scores = grid.cv_results_['mean_test_score']\n",
    "print(grid_mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can plot the scores to get an overview of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-Validated Accuracy')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.plot(k_range, grid_mean_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So again we get exactly the same graph. Lets check whats the best parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'n_neighbors': 13}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning multiple Parametes simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Grid Search we are also capable of tuning multiple parameters simultaneously. For example consider we want to find the best score for:\n",
    "1. the number of neighbours `n_neighbors` and\n",
    "2. the weights option of KNN `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0          0.960000        0.053333   \n",
       "1          0.960000        0.053333   \n",
       "2          0.953333        0.052068   \n",
       "3          0.960000        0.053333   \n",
       "4          0.966667        0.044721   \n",
       "5          0.966667        0.044721   \n",
       "6          0.966667        0.044721   \n",
       "7          0.966667        0.044721   \n",
       "8          0.966667        0.044721   \n",
       "9          0.966667        0.044721   \n",
       "10         0.966667        0.044721   \n",
       "11         0.966667        0.044721   \n",
       "12         0.966667        0.044721   \n",
       "13         0.966667        0.044721   \n",
       "14         0.966667        0.044721   \n",
       "15         0.966667        0.044721   \n",
       "16         0.973333        0.032660   \n",
       "17         0.973333        0.032660   \n",
       "18         0.966667        0.044721   \n",
       "19         0.973333        0.032660   \n",
       "20         0.966667        0.044721   \n",
       "21         0.973333        0.032660   \n",
       "22         0.973333        0.032660   \n",
       "23         0.973333        0.044222   \n",
       "24         0.980000        0.030551   \n",
       "25         0.973333        0.032660   \n",
       "26         0.973333        0.044222   \n",
       "27         0.973333        0.032660   \n",
       "28         0.973333        0.032660   \n",
       "29         0.980000        0.030551   \n",
       "30         0.973333        0.032660   \n",
       "31         0.973333        0.032660   \n",
       "32         0.973333        0.032660   \n",
       "33         0.980000        0.030551   \n",
       "34         0.980000        0.030551   \n",
       "35         0.973333        0.032660   \n",
       "36         0.973333        0.032660   \n",
       "37         0.980000        0.030551   \n",
       "38         0.980000        0.030551   \n",
       "39         0.966667        0.044721   \n",
       "40         0.966667        0.033333   \n",
       "41         0.966667        0.044721   \n",
       "42         0.966667        0.033333   \n",
       "43         0.966667        0.044721   \n",
       "44         0.973333        0.032660   \n",
       "45         0.973333        0.032660   \n",
       "46         0.960000        0.044222   \n",
       "47         0.973333        0.032660   \n",
       "48         0.966667        0.033333   \n",
       "49         0.973333        0.032660   \n",
       "50         0.960000        0.044222   \n",
       "51         0.966667        0.044721   \n",
       "52         0.966667        0.044721   \n",
       "53         0.980000        0.030551   \n",
       "54         0.953333        0.042687   \n",
       "55         0.973333        0.032660   \n",
       "56         0.953333        0.042687   \n",
       "57         0.973333        0.032660   \n",
       "58         0.953333        0.042687   \n",
       "59         0.966667        0.033333   \n",
       "\n",
       "                                        params  \n",
       "0     {'n_neighbors': 1, 'weights': 'uniform'}  \n",
       "1    {'n_neighbors': 1, 'weights': 'distance'}  \n",
       "2     {'n_neighbors': 2, 'weights': 'uniform'}  \n",
       "3    {'n_neighbors': 2, 'weights': 'distance'}  \n",
       "4     {'n_neighbors': 3, 'weights': 'uniform'}  \n",
       "5    {'n_neighbors': 3, 'weights': 'distance'}  \n",
       "6     {'n_neighbors': 4, 'weights': 'uniform'}  \n",
       "7    {'n_neighbors': 4, 'weights': 'distance'}  \n",
       "8     {'n_neighbors': 5, 'weights': 'uniform'}  \n",
       "9    {'n_neighbors': 5, 'weights': 'distance'}  \n",
       "10    {'n_neighbors': 6, 'weights': 'uniform'}  \n",
       "11   {'n_neighbors': 6, 'weights': 'distance'}  \n",
       "12    {'n_neighbors': 7, 'weights': 'uniform'}  \n",
       "13   {'n_neighbors': 7, 'weights': 'distance'}  \n",
       "14    {'n_neighbors': 8, 'weights': 'uniform'}  \n",
       "15   {'n_neighbors': 8, 'weights': 'distance'}  \n",
       "16    {'n_neighbors': 9, 'weights': 'uniform'}  \n",
       "17   {'n_neighbors': 9, 'weights': 'distance'}  \n",
       "18   {'n_neighbors': 10, 'weights': 'uniform'}  \n",
       "19  {'n_neighbors': 10, 'weights': 'distance'}  \n",
       "20   {'n_neighbors': 11, 'weights': 'uniform'}  \n",
       "21  {'n_neighbors': 11, 'weights': 'distance'}  \n",
       "22   {'n_neighbors': 12, 'weights': 'uniform'}  \n",
       "23  {'n_neighbors': 12, 'weights': 'distance'}  \n",
       "24   {'n_neighbors': 13, 'weights': 'uniform'}  \n",
       "25  {'n_neighbors': 13, 'weights': 'distance'}  \n",
       "26   {'n_neighbors': 14, 'weights': 'uniform'}  \n",
       "27  {'n_neighbors': 14, 'weights': 'distance'}  \n",
       "28   {'n_neighbors': 15, 'weights': 'uniform'}  \n",
       "29  {'n_neighbors': 15, 'weights': 'distance'}  \n",
       "30   {'n_neighbors': 16, 'weights': 'uniform'}  \n",
       "31  {'n_neighbors': 16, 'weights': 'distance'}  \n",
       "32   {'n_neighbors': 17, 'weights': 'uniform'}  \n",
       "33  {'n_neighbors': 17, 'weights': 'distance'}  \n",
       "34   {'n_neighbors': 18, 'weights': 'uniform'}  \n",
       "35  {'n_neighbors': 18, 'weights': 'distance'}  \n",
       "36   {'n_neighbors': 19, 'weights': 'uniform'}  \n",
       "37  {'n_neighbors': 19, 'weights': 'distance'}  \n",
       "38   {'n_neighbors': 20, 'weights': 'uniform'}  \n",
       "39  {'n_neighbors': 20, 'weights': 'distance'}  \n",
       "40   {'n_neighbors': 21, 'weights': 'uniform'}  \n",
       "41  {'n_neighbors': 21, 'weights': 'distance'}  \n",
       "42   {'n_neighbors': 22, 'weights': 'uniform'}  \n",
       "43  {'n_neighbors': 22, 'weights': 'distance'}  \n",
       "44   {'n_neighbors': 23, 'weights': 'uniform'}  \n",
       "45  {'n_neighbors': 23, 'weights': 'distance'}  \n",
       "46   {'n_neighbors': 24, 'weights': 'uniform'}  \n",
       "47  {'n_neighbors': 24, 'weights': 'distance'}  \n",
       "48   {'n_neighbors': 25, 'weights': 'uniform'}  \n",
       "49  {'n_neighbors': 25, 'weights': 'distance'}  \n",
       "50   {'n_neighbors': 26, 'weights': 'uniform'}  \n",
       "51  {'n_neighbors': 26, 'weights': 'distance'}  \n",
       "52   {'n_neighbors': 27, 'weights': 'uniform'}  \n",
       "53  {'n_neighbors': 27, 'weights': 'distance'}  \n",
       "54   {'n_neighbors': 28, 'weights': 'uniform'}  \n",
       "55  {'n_neighbors': 28, 'weights': 'distance'}  \n",
       "56   {'n_neighbors': 29, 'weights': 'uniform'}  \n",
       "57  {'n_neighbors': 29, 'weights': 'distance'}  \n",
       "58   {'n_neighbors': 30, 'weights': 'uniform'}  \n",
       "59  {'n_neighbors': 30, 'weights': 'distance'}  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'n_neighbors': 13, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now want to fit again to a new datum `grid` will automatically use the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortcut: GridSearchCV automatically refits the best model using all of the data\n",
    "grid.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomizedSearchCV to  Reducing computational expense\n",
    "\n",
    "Searching many different parameters at once may be computationally infeasible. `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_dist:  {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(\"param_dist: \", param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: Specify a continuous distribution (rather than a list of values) for any continous parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 15}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score                                      params\n",
       "0         0.973333        0.032660  {'weights': 'distance', 'n_neighbors': 16}\n",
       "1         0.966667        0.033333   {'weights': 'uniform', 'n_neighbors': 22}\n",
       "2         0.980000        0.030551   {'weights': 'uniform', 'n_neighbors': 18}\n",
       "3         0.966667        0.044721   {'weights': 'uniform', 'n_neighbors': 27}\n",
       "4         0.953333        0.042687   {'weights': 'uniform', 'n_neighbors': 29}\n",
       "5         0.973333        0.032660  {'weights': 'distance', 'n_neighbors': 10}\n",
       "6         0.966667        0.044721  {'weights': 'distance', 'n_neighbors': 22}\n",
       "7         0.973333        0.044222   {'weights': 'uniform', 'n_neighbors': 14}\n",
       "8         0.973333        0.044222  {'weights': 'distance', 'n_neighbors': 12}\n",
       "9         0.973333        0.032660   {'weights': 'uniform', 'n_neighbors': 15}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
    "rand.fit(X, y)\n",
    "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with just 10 iterations we again found the best score from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'weights': 'uniform', 'n_neighbors': 18}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run `RandomSearchCV` multiple times to check whether there is a better score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98, 0.98, 0.973, 0.98, 0.98, 0.98, 0.973, 0.98, 0.98, 0.98, 0.98, 0.98, 0.973, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.973]\n"
     ]
    }
   ],
   "source": [
    "# run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
    "best_scores = []\n",
    "for _ in range(20):\n",
    "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, return_train_score=False)\n",
    "    rand.fit(X, y)\n",
    "    best_scores.append(round(rand.best_score_, 3))\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, 20 times 10 iterations did not find any better paramter set than just 1 times 10 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
